{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from matplotlib.patches import Rectangle\n",
    "plt.style.use('seaborn-deep')\n",
    "from scipy.stats import norm\n",
    "from matplotlib.pyplot import figure\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "os.chdir('/Users/denislukanov/Desktop/webb_traders_task/test_data_1_1_1')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data = pd.read_csv('market_data.csv')\n",
    "#Calculate mid_price\n",
    "market_data['mid_price']=(market_data['bid_price']+market_data['ask_price'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f6da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4957dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "print(market_data.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating dollar quantity\n",
    "orders = pd.read_csv('orders.csv')\n",
    "orders['dollar_quantity']=orders['price']*orders['quantity']\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "print(orders.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple EDA of order's status\n",
    "orders['order_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out unfilled orders\n",
    "filtered_df_fill = orders[(orders['order_status']=='CREATE')&(orders['order_status'].shift(periods=1)=='FILL')]\n",
    "filtered_df_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef23e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing side of shor-sell\n",
    "filtered_df_fill.loc[filtered_df_fill['side'] == 'SELL', 'dollar_quantity'] *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62284c42",
   "metadata": {},
   "source": [
    "### I/ Market Risk\n",
    "\n",
    "a) Define what kind of metrics you would need to monitor the market risk of the cash equity strategy\n",
    "\n",
    "b) Using the data provided in file 1 and file 2, implement in Python one of the relevant metric you suggested\n",
    "\n",
    "c) Still using the Python code, how would you make your code more generic to include a wider range of risk metrics\n",
    "\n",
    "d) Run the calculation for your risk metric of choice and comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c666bef",
   "metadata": {},
   "source": [
    "### The idea main behind the solution for the 1st problem is  the following: \n",
    "   A) Calculate net exposure for each symbol\n",
    "   \n",
    "   B) Apply chosen risk metric for the net exposure\n",
    "   \n",
    "   C) Make dynamic calculation dollar value on a symbol level on a filled-orders dataset\n",
    "   \n",
    "   D) The calculated risk exposure should be monitored vs prestablished risk limits and or Risk-Policy guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe2f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of net exposure\n",
    "net_positions = {}\n",
    "for index, row in filtered_df_fill.iterrows():\n",
    "    symbol = row['symbol']\n",
    "    quantity = row['dollar_quantity']\n",
    "    if symbol not in net_positions:\n",
    "        net_positions[symbol] = 0\n",
    "    net_positions[symbol] += quantity\n",
    "    filtered_df_fill.at[index, 'net_position'] = net_positions[symbol]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd763c",
   "metadata": {},
   "source": [
    "### Motivation for choosing CVaR risk metric\n",
    "\n",
    "Value at Risk (VaR) and Conditional Value at Risk (CVaR) are both risk measures used to estimate the potential losses of an investment or portfolio over a specific time frame.  \n",
    "\n",
    "There are some differences between the two measures:\n",
    "\n",
    "1) VaR measures the potential loss of an investment or portfolio at a specific confidence level, whereas CVaR measures the expected loss beyond the VaR breakpoint.\n",
    "\n",
    "2) CVaR is a coherent risk measure, which means it is suitable for portfolio optimization and risk management. VaR, on the other hand, is not a coherent risk measure.\n",
    "\n",
    "Unlike VaR, which only considers the worst loss at a specific confidence level, CVaR focuses on the average loss in the worst-case scenarios, providing a more comprehensive view of the tail risk.\n",
    "CVaR is less sensitive to extreme outliers compared to VaR, making it a more robust risk measure for assets with non-normal distributions and fat tails.\n",
    "\n",
    "Ultimately, I choose CVaR because it provides a more comprehensive view of the tail risk and is more suitable for  risk management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ad02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cvar(mid_prices, alpha):\n",
    "    \"\"\"\n",
    "    function that calculates VaR and CVaR the Conditional Value at Risk (CVar) of a mid-price for a given significance level (alpha).\n",
    "    \"\"\"\n",
    "    # calculate daily returns from mid prices\n",
    "    daily_returns = mid_prices.pct_change()\n",
    "    \n",
    "    # find VaR (Value at Risk) at specified level\n",
    "    var = daily_returns.quantile(q=alpha)\n",
    "    \n",
    "    # filter returns below VaR, if any\n",
    "    daily_returns_cvar = daily_returns[daily_returns < var]\n",
    "    \n",
    "    # if the returns_cvar is empty \n",
    "    if daily_returns_cvar.empty or daily_returns_cvar.var() == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate CVaR (Conditional Value at Risk) and return\n",
    "    cvar = - daily_returns_cvar.mean()\n",
    "    return cvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed152e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculation test for one symbol\n",
    "# for i in range(len(filtered_df_fill[filtered_df_fill['symbol']==\"ACN\"])):\n",
    "#     print(market_data[(market_data['timestamp'] < filtered_df_fill['timestamp'].iloc[i]) & (market_data['symbol'] == 'ACN')].tail(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70948f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heavy part of the algorithm in terms of calcualtion speed/time\n",
    "\n",
    "cvar_data=[]\n",
    "\"\"\"\n",
    "Dynamic market risk assesment with a window given last 100 observations of mid_price before the timestamp of actual filled orders\n",
    "Exposure risk calculation is done on securities level because securities orders are filled on this level without taken into consideration portfolio diversification\n",
    "Window size and alpha are hyperparamenters that could be finr tuned manually\n",
    "\"\"\"\n",
    "\n",
    "for symbol in tqdm(filtered_df_fill['symbol'].unique()):\n",
    "    for i, row in filtered_df_fill[filtered_df_fill['symbol'] == symbol].iterrows():\n",
    "        last_10 = market_data[(market_data['timestamp'] < row['timestamp']) & (market_data['symbol'] == symbol)].tail(100)\n",
    "        net_position = row['net_position']\n",
    "        cvar = calculate_cvar(last_10['mid_price'], 0.05) * net_position * 100\n",
    "        filtered_df_fill.loc[i, 'CVar'] = cvar\n",
    "        cvar_data.append(cvar)\n",
    "        print(symbol)\n",
    "        print(last_10['timestamp'].values[-1]) \n",
    "        print(cvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding calculated CVaR values into the main dataset\n",
    "filtered_df_fill['CVar']=cvar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd8179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855617ad",
   "metadata": {},
   "source": [
    "### II/ Market Surveillance\n",
    "\n",
    " a) You now want to know whether the algo is misbehaving (from a market regulation perspective). What kind of metrics would you look at?\n",
    "\n",
    " b) In a similar fashion as above, implement in Python one of those metrics\n",
    "\n",
    " c) Run the calculation for your metric of choice and comment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d273734",
   "metadata": {},
   "source": [
    "### Theorectical inference: the main groups of activitivies that could potentially fall under financial market misbehaviour and/or manipulation can be aggregated in the following main groups:  \n",
    "#### Abnormal Trading Activity: \n",
    "Monitoring for abnormal trading activity, such as sudden price movements or abnormal trading patterns, can help detect potential market manipulation. Statistical analysis, pattern recognition, and anomaly detection algorithms are used to identify potential manipulative behavior. \n",
    "#### Volume: \n",
    "Monitoring the trading volume of a security or market can help identify potential market manipulation. Unusually high or low trading volumes may indicate manipulative behavior\n",
    "#### Order Book Imbalances: \n",
    "Monitoring the order book imbalances, which is the difference between the number of buy and sell orders at a specific price level, can help identify potential market manipulation. Large imbalances may indicate manipulative behavior. \n",
    "#### Price Movements: \n",
    "Monitoring the price movements of a security or market can help identify potential market manipulation. Sudden and significant price movements that are not aligned with market fundamentals may indicate manipulative behavior. \n",
    "#### Correlations: \n",
    "Monitoring the correlations between different securities or markets can help identify potential market manipulation. Unusual correlations or patterns may indicate manipulative behavior \n",
    "\n",
    "It should be noted that these quantitative measures are not definitive proof of market manipulation, but they can provide valuable insights into potential manipulative behavior. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0542b0",
   "metadata": {},
   "source": [
    "### The idea main behind the solution for the 2nd problem is  the following: \n",
    "   A) I choose price and quantity data to analyse for potential manipulation\n",
    "   \n",
    "   B) Visualise chosen on a) data for each sympol\n",
    "   \n",
    "   C) Apply Isolation forest algo to detect potential manipulation trades\n",
    "   \n",
    "   D) Visualise and map potentially manipulative reading activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23705051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this problem I create a new link to the filtered dataset \n",
    "\n",
    "df=filtered_df_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344082b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First thing is to visualise the data on a symbol level\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "symbols = df['symbol'].unique()\n",
    "\n",
    "# Define a list of colors to use for the plots\n",
    "colors = ['blue', 'green', 'red', 'orange', 'purple']\n",
    "\n",
    "for i, symbol in enumerate(symbols):\n",
    "    symbol_data = df[df['symbol'] == symbol]\n",
    "    \n",
    "    # Plot for Quantity\n",
    "    plt.figure()\n",
    "    plt.plot(symbol_data['date'], symbol_data['quantity'], color=colors[2 % 4])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Quantity')\n",
    "    plt.title('{} Quantity'.format(symbol))\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot for Price\n",
    "    plt.figure()\n",
    "    plt.plot(symbol_data['date'], symbol_data['price'], color=colors[1%4])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title('{} Price'.format(symbol))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Perform Anomaly Detection\n",
    "symbols = df['symbol'].unique()\n",
    "anomalies = pd.DataFrame(columns=df.columns)\n",
    "for symbol in symbols:\n",
    "    symbol_df = df[df['symbol'] == symbol]\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    normalized_data = scaler.fit_transform(symbol_df[['price', 'quantity']])\n",
    "    # Apply Isolation Forest algorithm\n",
    "    clf = IsolationForest(contamination=0.05)\n",
    "    clf.fit(normalized_data)\n",
    "    anomaly_scores = clf.decision_function(normalized_data)\n",
    "    # Identify anomalies\n",
    "    symbol_anomalies = symbol_df[anomaly_scores < 0]\n",
    "    anomalies = pd.concat([anomalies, symbol_anomalies])\n",
    "\n",
    "# Step 2: Create Separate Plots for Each Symbol\n",
    "for symbol in symbols:\n",
    "    symbol_df = df[df['symbol'] == symbol]\n",
    "    symbol_anomalies = anomalies[anomalies['symbol'] == symbol]\n",
    "    # Plot Price\n",
    "    plt.plot(symbol_df['date'], symbol_df['price'], label='Price')\n",
    "    plt.scatter(symbol_anomalies['date'], symbol_anomalies['price'], color='red', label='Anomaly')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'{symbol} Stock Prices')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # Plot Quantity\n",
    "    plt.plot(symbol_df['date'], symbol_df['quantity'], label='Quantity')\n",
    "    plt.scatter(symbol_anomalies['date'], symbol_anomalies['quantity'], color='red', label='Anomaly')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Quantity')\n",
    "    plt.title(f'{symbol} Stock Quantities')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e1ebc5",
   "metadata": {},
   "source": [
    "### From the above calculations and visualisation we can derive following conclusions:\n",
    " \n",
    "  a) Algo is good in capturing extreme values for quantity (we observe more extreme movemets in quantity vs price)\n",
    "  \n",
    "  b) Algo is good at capturing \"turning points\" points in price (price moves in a more smooth maner than quantity)\n",
    "  \n",
    "  c) By mapping turning points in price with extreme quantity levels we get a higher probabilty of detecting manipulative trades on the particulat symbol "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4436ae1e",
   "metadata": {},
   "source": [
    "### III/ Derivatives\n",
    " f) Let's assume that instead of a cash equity strategy, the trader decides to trade a directional alpha on options. \n",
    "\n",
    "What additional risk metrics would you suggest in addition to question a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ce452",
   "metadata": {},
   "source": [
    "### Solution for problem 3:\n",
    "As soon as we are adding derivatives to our portfolio we need to start tracking at least two characteristics:\n",
    "\n",
    "A) Delta of the particular symbol that charaterises change in option price vs price for symbol (mathematically - 1st derivative)\n",
    "\n",
    "B) Gamma that charaterises change of the option's delta with vs price for symbol (mathematically - 2nd derivative)\n",
    "\n",
    "C) Keep constant track of each metric given our Risk appetite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db426eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
